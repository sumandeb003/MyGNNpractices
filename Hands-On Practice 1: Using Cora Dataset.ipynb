{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20dc944b",
   "metadata": {},
   "source": [
    "# Obtaining the Dataset: Cora\n",
    "\n",
    "PyTorch Geometric is an extension library to the popular deep learning framework PyTorch, and consists of various methods and utilities to ease the implementation of Graph Neural Networks.\n",
    "\n",
    "In this hands-on exercise, I will demonstrate the training and testing of a Graph Neural Network (GNN). To demonstrate, I make use of the Cora dataset (available in PyTorch Geometric framework), which is a citation network where nodes represent documents. Each node is described by a 1433-dimensional bag-of-words feature vector. Two documents are connected if there exists a citation link between them. The ground-truth labels of only a small subset of nodes are given. The task is to infer the labels (7 in total) for all the remaining nodes (**transductive learning**). This dataset was first introduced by [Yang et al. (2016)](https://arxiv.org/abs/1603.08861) as one of the datasets of the Planetoid benchmark suite. The other citation network datasets present in Planetoid are \"CiteSeer\" and \"PubMed\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ebe555e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Cora():\n",
      "======================\n",
      "Number of graphs: 1\n",
      "Number of classes: 7\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora', transform=NormalizeFeatures())\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('======================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of classes: {dataset.num_classes}')#number of node classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0179e381",
   "metadata": {},
   "source": [
    "PyTorch Geometric provides a **Data** class. An object of the **Data** class is a homogeneous graph. Such an object can hold node-level, link-level and graph-level attributes. \n",
    "\n",
    "In general, **Data** tries to mimic the behavior of a regular Python dictionary. \n",
    "\n",
    "Some of the commonly useful properties of this class and its objects are:\n",
    "1. **num_node_features**: int, used in defining the \n",
    "2. **num_nodes**: int\n",
    "3. **num_edge_features**: int\n",
    "4. **num_edges**: int\n",
    "5. **num_classes**: int\n",
    "\n",
    "6. num_edge_types: int\n",
    "7. num_node_types: int\n",
    "\n",
    "Some of the useful methods of this class and its objects are:\n",
    "1. .is_undirected()\n",
    "2. .has_self_loops()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8e677cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-th graph: Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n",
      "------------\n",
      "Number of nodes: 2708\n",
      "Number of node features: 1433\n",
      "Number of edges: 10556\n",
      "Number of edge features: 0\n",
      "Average node degree: 3.90\n",
      "Number of training nodes: 140\n",
      "Number of validation nodes: 500\n",
      "Number of test nodes: 1000\n",
      "Has isolated nodes(nodes without edges): False\n",
      "Has self-loops: False\n",
      "Is undirected: True\n"
     ]
    }
   ],
   "source": [
    "for (i,graph) in zip(range(len(dataset)),dataset):\n",
    "        print(f'{i}-th graph: {graph}')\n",
    "        print(f'------------')\n",
    "        print(f'Number of nodes: {graph.num_nodes}')\n",
    "        print(f'Number of node features: {graph.num_node_features}')\n",
    "        print(f'Number of edges: {graph.num_edges}')\n",
    "        print(f'Number of edge features: {graph.num_edge_features}')\n",
    "        print(f'Average node degree: {graph.num_edges / graph.num_nodes:.2f}')\n",
    "        print(f'Number of training nodes: {graph.train_mask.sum()}')\n",
    "        print(f'Number of validation nodes: {graph.val_mask.sum()}')\n",
    "        print(f'Number of test nodes: {graph.test_mask.sum()}')\n",
    "        print(f'Has isolated nodes(nodes without edges): {graph.has_isolated_nodes()}')\n",
    "        print(f'Has self-loops: {graph.has_self_loops()}')\n",
    "        print(f'Is undirected: {graph.is_undirected()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3e9cef",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\n",
    "1. The number of training nodes is few: **140**.\n",
    "\n",
    "2. You can see that this graph holds the attributes `val_mask` and `test_mask` denoting which nodes should be used for validation and testing.\n",
    "\n",
    "3. Furthermore, notice the use of data transformations via `transform=NormalizeFeatures()`. It row-normalizes the bag-of-words input feature vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b426ecc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 4,  ..., 3, 3, 3])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].y #contains the ground-truth label of each of the 2708 nodes in the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e8acd0b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2708"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[0].y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "72b823ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "len(np.unique(np.array(dataset[0].y)))#np.unique() is a utility from the numpy library that removes duplicates in a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a48c17f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].x #a tensor containing the node embeddings. Each embedding corresponds to one of the 7 ground-truth labels of the nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6dbe96a4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2708"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[0].x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0a92872a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0000, 0.0476,  ..., 0.0000, 0.0000, 0.0000])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].x[2700] #embeddings of the 2701th node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755c5215",
   "metadata": {},
   "source": [
    "By printing '**edge_index**', we can understand how PyG represents graph connectivity internally. We can see that for each edge, edge_index holds a tuple of two node indices, where the first value describes the node index of the source node and the second value describes the node index of the destination node of an edge.\n",
    "\n",
    "This representation is known as the **COO format** (co-ordinate format) commonly used for representing sparse matrices. Instead of holding the adjacency information in a dense representation, PyG represents graphs sparsely, which refers to only holding the coordinates/values for which entries are non-zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1173a79e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,    0,    0,  ..., 2707, 2707, 2707],\n",
       "        [ 633, 1862, 2582,  ...,  598, 1473, 2706]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "426135cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[0].edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ce87b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,  633],\n",
       "        [   0, 1862],\n",
       "        [   0, 2582],\n",
       "        ...,\n",
       "        [2707,  598],\n",
       "        [2707, 1473],\n",
       "        [2707, 2706]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.transpose(dataset[0].edge_index,0,1) #shows the source and the destination nodes of each edge in the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "cf0495d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0].edge_attr #Edge feature matrix (default: None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "8dbbe685",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0].pos #Node position matrix (default: None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f558f1",
   "metadata": {},
   "source": [
    "## Implementing a Graph Neural Network (GNN)\n",
    "\n",
    "In the following cell, we implement a 2-layered GNN. Each layer performs the following graph convolution operation ([Kipf et al. (2017)](https://arxiv.org/abs/1609.02907)):\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_v^{(\\ell + 1)} = \\mathbf{W}^{(\\ell + 1)} \\sum_{w \\in \\mathcal{N}(v) \\, \\cup \\, \\{ v \\}} \\frac{1}{c_{w,v}} \\cdot \\mathbf{x}_w^{(\\ell)}\n",
    "$$\n",
    "\n",
    "where, $\\mathbf{W}^{(\\ell + 1)}$ denotes a **trainable weight matrix** of shape `[num_output_features, num_input_features]` and $c_{w,v}$ refers to a fixed normalization coefficient for each edge.\n",
    "\n",
    "PyG implements this layer via its [`GCNConv`](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GCNConv) class, specifically the `forward` function in it. It is executed by passing in the node-feature representation `x` and the COO graph-connectivity representation `edge_index`.\n",
    "\n",
    "The Graph Neural Network (GNN) architecture is described in a child class `GCN` derived from the `torch.nn.Module` class of PyTorch. The `GCN` class contains the dimensions of individual convolution layers and the sequence of the convolution layers and non-linear activations (that follow each of the convolution layers). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5f8e403",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GCN(torch.nn.Module):#torch.nn.Module is the base class for all neural network modules in PyTorch \n",
    "    def __init__(self):#defines the layers of the GNN and initializes them\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)#GCNConv() performs message computation, aggregation of the messages, and then, updating of the node embeddings. The 1st parameter 'number of input features per node' and the 2nd argument 'number of features per output' are provided for initializing the parameters of the class GCNConv.\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, graph):#defines the computation flow of our network. An entire graph is fed to the GNN.\n",
    "        x, edge_index = graph.x, graph.edge_index#'x' represents the vector of node features and edge_index represents the adjacency matrix for connectivity\n",
    "\n",
    "        x = self.conv1(x, edge_index)#conv1.forward() gets called here. The arguments 'x' and 'edge_index' are passed as inputs to forward().\n",
    "        x = F.relu(x)#Applying Relu activation on the result of the above graph-convolution operation.\n",
    "        \n",
    "        x = F.dropout(x, training=self.training)#Randomly zero some of the elements of the input tensor 'x' with probability p(default: 0.5) using samples from a Bernoulli distribution.Also, the mode is set to 'training' because Dropout behaves differently during training and testing.\n",
    "        \n",
    "        x = self.conv2(x, edge_index)#conv2.forward() gets called here. The arguments 'x' and 'edge_index' are passed as inputs to forward().\n",
    "        return F.log_softmax(x, dim=1)#Applying softmax activation on the result of the above graph-convolution operation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f87f765",
   "metadata": {},
   "source": [
    "Then, we choose the device on which we want to deploy the GNN and the training dataset.\n",
    "\n",
    "A **torch.device** is an object representing the device on which a torch.Tensor is or will be allocated. The torch.device contains a device type ('cpu', 'cuda' or 'mps') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7104f29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172f14a3",
   "metadata": {},
   "source": [
    "Next, we move the GNN parameters to the chosen device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a9c47798",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615e2f99",
   "metadata": {},
   "source": [
    "Also, we move the dataset to the chosen device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "cf8a9dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset[0].to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd3ae1b",
   "metadata": {},
   "source": [
    "## Training the GNN\n",
    "\n",
    "Then, we choose the optimization algorithm (from the *torch.optim* package) for training/optimizing the parameters of our GNN. As an input, we provided *model.parameters()* to denote which parameters (tensors) to optimize. We also defined the decay constant and learning rate (lr).\n",
    "\n",
    "**NOTE:** During training, the weights (parameters) of the GNN are learnt and not the embeddings of the nodes. The GNN just predicts or computes the embeddings of the nodes using *neural message passing*. The GNN just maps the input node-embeddings to new embeddings. So, the GNN can be seen as graph transformer, *i.e.*, it transforms the input graph into output graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "0fc05fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453ed991",
   "metadata": {},
   "source": [
    "Next, we set the mode of GCN module (torch.nn.Module) to training. '*model.train()*' simple changes the '*self.training*' flag via '*self.training = training*' recursively for all modules. \n",
    "\n",
    "**Note**: By default, the mode is set to training and that is why they omit '*model.train()*' call. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "087ebc64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (conv1): GCNConv(1433, 16)\n",
       "  (conv2): GCNConv(16, 7)\n",
       ")"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c309fd44",
   "metadata": {},
   "source": [
    "We train the GCN module for 200 epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "f0f57cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()#Initializes the gradients to zero at the beginning of each epoch\n",
    "    \n",
    "    out = model(data)#Calls the 'forward' method in the class GCN and stores the output/prediction of the network for all nodes in a \n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])#Calculates the negative log likelihood loss (nll) between original ('data.y') and predicted data ('out') points\n",
    "    \n",
    "    loss.backward()#Backward pass for computing the gradients of the loss w.r.t to learnable parameters\n",
    "    optimizer.step()#Updates the learnt parameters at the end of each epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2174b3b1",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> **NOTE:**</span>\n",
    "\n",
    "**In each epoch, the entire training set is forwarded through the GNN.** \n",
    "\n",
    "**So, in an epoch, all the graphs in the training set are given as input to `train()`.**\n",
    "\n",
    "<span style=\"color:red\">**In `train()`, are the graphs input as an argument to `model()` one by one? Or, is the entire training set input as an argument to `model()` at once?** </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16f5e98",
   "metadata": {},
   "source": [
    "**Final node-embeddings computed by the trained GNN:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "941a5bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.5692, -2.9545, -2.4609,  ..., -3.9787, -4.8001, -3.9018],\n",
       "        [-3.5372, -3.8077, -4.6999,  ..., -0.1340, -3.4032, -4.1923],\n",
       "        [-3.5429, -4.7425, -5.0581,  ..., -0.1691, -5.2615, -3.5513],\n",
       "        ...,\n",
       "        [-0.9781, -1.1606, -4.4688,  ..., -4.2733, -2.5117, -2.1572],\n",
       "        [-3.4227, -3.6199, -4.1960,  ..., -2.3243, -6.3733, -4.8514],\n",
       "        [-3.1746, -3.6696, -3.3696,  ..., -2.4823, -5.3351, -3.9233]],\n",
       "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(data) #model(data) is the tensor containing the node embeddings computed by the GNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38027baf",
   "metadata": {},
   "source": [
    "## Testing the trained GNN\n",
    "\n",
    "Next, we set the mode of GCN module (torch.nn.Module) to testing. `eval()` is a method of the `torch.nn.module` class that sets the NN module (object of the `torch.nn.module` class or of classes derived from `torch.nn.module`) to testing or evaluation mode. This is equivalent to executing: ***model.train(mode=False)***. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "01118dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (conv1): GCNConv(1433, 16)\n",
       "  (conv2): GCNConv(16, 7)\n",
       ")"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ab86e277",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-5.3779, -4.6365, -3.7765, -0.0811, -3.6247, -6.8765, -4.3396],\n",
       "       device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(data)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "7b8f022d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3, device='cuda:0')"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(data)[0].argmax(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2f693edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.0887e+01, -1.3381e+01, -1.6949e+01, -1.3455e+01, -2.5868e-05,\n",
       "        -1.3200e+01, -1.2966e+01], device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(data)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b64a5304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4, device='cuda:0')"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(data)[1].argmax(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "fdebb0f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.3779, -4.6365, -3.7765, -0.0811, -3.6247, -6.8765, -4.3396],\n",
       "        [-4.0937, -4.6657, -5.3559, -3.9433, -0.0626, -6.1017, -4.7951]],\n",
       "       device='cuda:0', grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(data)[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "bef3a3ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 0, 1, 1, 0], device='cuda:0')"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(data)[0:2].argmax(dim=0) #dim 0 => along each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "3591e688",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4], device='cuda:0')"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(data)[0:2].argmax(dim=1) #dim 1 =>along each row (feature vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5e9879",
   "metadata": {},
   "source": [
    "Then, obtain the predicted label by storing the label corresponding to the node embedding that has max probability. Note that, as mentioned above, each of the 7 embeddings of a node corresponds to one of the 7 labels possible for a node. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ef80d57c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 4,  ..., 0, 3, 3], device='cuda:0')"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model(data).argmax(dim=1)\n",
    "pred #tensor containing list of indices of the largest features of each node in the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "934eb473",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2708"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "23b6e5b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False,  ...,  True,  True,  True], device='cuda:0')"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.test_mask #tensor that labels each of the 2708 nodes of the graph as a test sample or non-test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e4a9ef4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2708"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.test_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "f1f88707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2,\n",
       "        2, 1, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 5, 5, 5, 4, 5, 1, 1, 3, 0, 1, 1, 6,\n",
       "        2, 1, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5,\n",
       "        5, 5, 2, 2, 2, 2, 2, 6, 6, 3, 0, 0, 0, 0, 5, 0, 0, 0, 3, 0, 0, 6, 0, 0,\n",
       "        3, 3, 3, 3, 1, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 5, 5, 5, 5, 5, 5, 5, 5, 2, 2, 2, 4, 4, 4, 4, 4, 3, 2, 5, 5, 5, 5,\n",
       "        6, 5, 5, 5, 5, 6, 4, 4, 0, 0, 1, 0, 0, 0, 6, 6, 6, 6, 0, 6, 6, 0, 0, 0,\n",
       "        0, 0, 0, 0, 3, 0, 0, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 5, 5, 5, 5, 3, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        6, 6, 5, 6, 6, 5, 5, 5, 5, 0, 5, 0, 4, 0, 3, 3, 3, 2, 3, 1, 3, 3, 3, 3,\n",
       "        3, 3, 1, 3, 3, 4, 4, 4, 3, 3, 3, 3, 3, 3, 0, 3, 0, 0, 0, 0, 0, 5, 0, 5,\n",
       "        0, 0, 6, 6, 0, 6, 1, 3, 5, 5, 6, 6, 4, 4, 4, 4, 3, 3, 4, 4, 4, 3, 4, 4,\n",
       "        4, 1, 1, 1, 1, 0, 6, 0, 0, 0, 0, 0, 0, 0, 2, 0, 5, 5, 5, 3, 3, 3, 3, 3,\n",
       "        0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3,\n",
       "        1, 1, 1, 1, 1, 0, 0, 0, 6, 0, 0, 0, 0, 0, 1, 1, 0, 6, 6, 5, 6, 2, 3, 3,\n",
       "        0, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 0, 6, 0, 6, 6, 0, 0, 3, 3,\n",
       "        3, 3, 3, 1, 1, 1, 3, 3, 3, 5, 2, 6, 3, 0, 0, 0, 0, 6, 6, 6, 6, 6, 3, 3,\n",
       "        6, 6, 6, 2, 2, 1, 0, 0, 0, 1, 6, 3, 3, 6, 0, 0, 0, 0, 0, 0, 5, 5, 0, 4,\n",
       "        0, 0, 6, 3, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 5, 6, 1, 0,\n",
       "        3, 3, 3, 3, 3, 6, 1, 0, 2, 2, 4, 4, 4, 4, 4, 5, 6, 3, 3, 4, 0, 0, 0, 5,\n",
       "        4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 1, 1, 3, 1, 6, 5, 2, 3, 4,\n",
       "        4, 4, 4, 0, 4, 4, 0, 0, 4, 5, 5, 5, 5, 5, 5, 5, 0, 0, 6, 2, 0, 5, 6, 3,\n",
       "        5, 5, 5, 5, 5, 4, 4, 4, 4, 6, 4, 0, 3, 4, 0, 5, 1, 3, 4, 3, 3, 3, 3, 2,\n",
       "        3, 3, 3, 0, 0, 1, 1, 3, 6, 3, 1, 3, 0, 0, 1, 5, 1, 1, 5, 1, 1, 1, 0, 1,\n",
       "        0, 0, 2, 4, 4, 4, 3, 3, 3, 3, 0, 3, 3, 4, 4, 0, 4, 4, 4, 4, 4, 3, 3, 0,\n",
       "        0, 0, 3, 3, 3, 3, 4, 5, 0, 2, 2, 3, 3, 3, 3, 3, 3, 0, 5, 5, 4, 1, 4, 4,\n",
       "        4, 4, 4, 4, 0, 3, 4, 4, 6, 2, 2, 2, 2, 4, 0, 0, 0, 0, 3, 4, 4, 4, 3, 3,\n",
       "        0, 5, 4, 5, 0, 3, 3, 3, 3, 2, 3, 2, 4, 4, 0, 0, 3, 2, 6, 0, 0, 0, 3, 5,\n",
       "        5, 1, 3, 4, 4, 1, 4, 4, 6, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 1,\n",
       "        2, 0, 6, 6, 2, 6, 6, 3, 2, 6, 2, 4, 4, 4, 2, 5, 5, 2, 2, 3, 4, 4, 4, 3,\n",
       "        2, 3, 1, 6, 6, 5, 0, 4, 4, 6, 3, 1, 1, 4, 0, 5, 2, 3, 3, 3, 5, 5, 4, 0,\n",
       "        3, 3, 0, 2, 1, 1, 5, 2, 3, 3, 5, 0, 2, 3, 2, 2, 5, 6, 4, 3, 4, 3, 1, 2,\n",
       "        4, 2, 4, 5, 5, 3, 2, 3, 1, 3, 3, 3, 4, 5, 4, 3, 3, 3, 1, 3, 0, 0, 2, 4,\n",
       "        4, 4, 3, 3, 1, 0, 2, 3, 1, 2, 2, 3, 2, 0, 3, 4, 4, 3, 3, 3, 3, 4, 3, 2,\n",
       "        3, 3, 3, 0, 0, 3, 3, 3, 3, 2, 3, 4, 2, 2, 3, 4, 3, 3, 4, 1, 5, 3, 4, 3,\n",
       "        2, 2, 1, 3, 2, 3, 4, 4, 6, 3, 2, 2, 6, 3, 3, 0, 2, 3, 2, 3, 2, 5, 2, 2,\n",
       "        0, 5, 6, 4, 3, 3, 3, 2, 5, 3, 3, 4, 3, 3, 3, 3, 3, 4, 6, 6, 5, 2, 2, 2,\n",
       "        5, 4, 4, 4, 4, 6, 3, 2, 2, 0, 0, 0, 1, 2, 2, 3, 0, 4, 4, 3, 1, 4, 4, 3,\n",
       "        3, 0, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 2, 3, 3, 3, 3, 3, 2,\n",
       "        6, 3, 4, 4, 3, 3, 3, 3, 3, 3, 0, 3, 2, 0, 3, 3], device='cuda:0')"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[data.test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "e44e52db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred[data.test_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "3e5afe21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "bc3f47e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 4,  ..., 3, 3, 3], device='cuda:0')"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "f6b0e1d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2708"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "38a916f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2,\n",
       "        2, 2, 2, 1, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 5, 2, 2, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 3, 4, 4, 4, 4, 1, 1, 3, 1, 0, 3, 0,\n",
       "        2, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5,\n",
       "        5, 5, 2, 2, 2, 2, 1, 6, 6, 3, 0, 0, 5, 0, 5, 0, 3, 5, 3, 0, 0, 6, 0, 6,\n",
       "        3, 3, 1, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 5, 5, 5, 5, 5, 5, 5, 5, 2, 2, 2, 4, 4, 4, 0, 3, 3, 2, 5, 5, 5, 5,\n",
       "        6, 5, 5, 5, 5, 0, 4, 4, 4, 0, 0, 5, 0, 0, 6, 6, 6, 6, 6, 6, 0, 0, 0, 0,\n",
       "        3, 0, 0, 0, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 5, 5, 5, 5, 3, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        6, 6, 5, 6, 6, 3, 5, 5, 5, 0, 5, 0, 4, 4, 3, 3, 3, 2, 2, 1, 3, 3, 3, 3,\n",
       "        3, 3, 5, 3, 3, 4, 4, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 6, 3, 6, 0, 5, 0, 0,\n",
       "        4, 0, 6, 5, 5, 0, 1, 3, 3, 5, 6, 5, 3, 3, 4, 3, 3, 3, 3, 3, 4, 3, 3, 4,\n",
       "        3, 1, 1, 0, 1, 0, 6, 0, 0, 0, 0, 0, 0, 0, 5, 0, 5, 5, 5, 3, 3, 3, 3, 3,\n",
       "        0, 0, 0, 2, 0, 0, 0, 3, 3, 3, 3, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 0, 1, 3,\n",
       "        1, 1, 1, 1, 1, 0, 0, 0, 5, 5, 5, 5, 3, 5, 1, 1, 3, 6, 6, 5, 6, 2, 3, 3,\n",
       "        0, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 4, 3, 3, 4, 0, 6, 0, 6, 6, 0, 0, 3, 3,\n",
       "        3, 3, 3, 1, 1, 1, 3, 3, 3, 3, 5, 6, 3, 4, 6, 0, 0, 6, 6, 6, 6, 6, 3, 3,\n",
       "        6, 6, 5, 2, 1, 2, 1, 0, 0, 6, 6, 2, 3, 3, 5, 0, 0, 0, 0, 0, 5, 5, 0, 3,\n",
       "        5, 0, 6, 3, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 1, 6, 1, 0,\n",
       "        3, 3, 3, 3, 3, 6, 1, 0, 2, 2, 4, 4, 4, 4, 4, 5, 6, 3, 3, 0, 0, 0, 0, 5,\n",
       "        4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 0, 3, 4, 4, 4, 1, 1, 3, 1, 1, 5, 1, 3, 4,\n",
       "        4, 4, 4, 4, 4, 4, 0, 0, 0, 5, 5, 5, 5, 5, 0, 5, 3, 0, 6, 2, 0, 5, 3, 3,\n",
       "        5, 5, 5, 5, 5, 4, 4, 0, 4, 0, 4, 0, 3, 4, 4, 4, 1, 3, 3, 3, 3, 3, 4, 2,\n",
       "        3, 3, 3, 0, 0, 2, 3, 3, 3, 3, 1, 1, 3, 0, 1, 4, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "        0, 0, 2, 4, 4, 4, 3, 3, 3, 4, 0, 3, 3, 3, 3, 0, 3, 3, 4, 4, 4, 4, 4, 4,\n",
       "        0, 4, 3, 2, 0, 3, 4, 5, 0, 2, 2, 3, 3, 3, 3, 3, 2, 3, 5, 5, 4, 1, 4, 4,\n",
       "        4, 3, 4, 4, 0, 4, 4, 4, 5, 2, 2, 2, 2, 4, 6, 6, 6, 6, 3, 4, 4, 4, 1, 3,\n",
       "        0, 3, 3, 5, 0, 2, 3, 3, 3, 3, 3, 2, 4, 4, 0, 0, 3, 2, 6, 6, 0, 3, 3, 3,\n",
       "        5, 1, 3, 4, 4, 2, 4, 4, 4, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2,\n",
       "        2, 0, 6, 6, 5, 6, 6, 3, 2, 6, 3, 4, 4, 4, 2, 6, 6, 0, 0, 3, 0, 4, 4, 3,\n",
       "        2, 3, 1, 6, 6, 5, 3, 4, 3, 5, 3, 1, 1, 3, 4, 5, 2, 3, 3, 3, 4, 5, 4, 0,\n",
       "        3, 3, 0, 2, 1, 1, 5, 2, 3, 3, 5, 0, 2, 3, 2, 2, 5, 5, 4, 3, 4, 3, 2, 2,\n",
       "        4, 2, 4, 5, 5, 3, 2, 3, 1, 0, 3, 3, 4, 5, 4, 3, 3, 3, 3, 3, 0, 1, 2, 4,\n",
       "        4, 4, 3, 3, 3, 5, 2, 3, 2, 2, 2, 3, 2, 2, 0, 4, 4, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 0, 0, 3, 0, 3, 0, 2, 3, 4, 1, 2, 5, 4, 3, 3, 3, 1, 5, 3, 4, 3,\n",
       "        2, 2, 1, 3, 3, 3, 3, 3, 6, 3, 3, 3, 6, 3, 3, 3, 2, 3, 2, 4, 2, 4, 2, 2,\n",
       "        1, 5, 6, 4, 3, 3, 3, 2, 5, 3, 3, 4, 3, 3, 3, 3, 3, 4, 6, 0, 3, 2, 2, 2,\n",
       "        5, 4, 4, 4, 4, 6, 3, 2, 2, 0, 2, 2, 2, 2, 2, 3, 4, 4, 4, 3, 3, 4, 4, 3,\n",
       "        3, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 2, 3, 3, 3, 2, 6, 2,\n",
       "        3, 3, 4, 4, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3], device='cuda:0')"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y[data.test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "f898fbae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.y[data.test_mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe00cc6d",
   "metadata": {},
   "source": [
    "Compute the total number of correct predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "e77415d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(801, device='cuda:0')"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035bbaba",
   "metadata": {},
   "source": [
    "Finally, we compute and print the accuracy performance of the GNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "26a96a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8010\n"
     ]
    }
   ],
   "source": [
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda82dee",
   "metadata": {},
   "source": [
    "**NOTE:** \n",
    "Without normalizing the node features, the accuracy of the same GNN (with everything else unchanged) was 0.8070, *i.e.*, the GNN predicted the labels of 807 nodes correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6e0282",
   "metadata": {},
   "source": [
    "## Comparing the Performance of the GNN with that of a Multi-Layered Perceptron (MLP)\n",
    "\n",
    "In theory, the category of a document can solely be based on and inferred from its content, *i.e.* it's bag-of-words feature representation, without taking any relational information into account.\n",
    "\n",
    "Let's verify that by constructing a simple MLP that operates solely on the node features (using shared weights across all nodes):\n",
    "\n",
    "The MLP here is defined by two linear layers and enhanced by ReLU non-linearity and dropout.\n",
    "Here, at first, the 1433-dimensional feature vector is reduced to a low-dimensional embedding (`hidden_channels=16`), while the second linear layer acts as a classifier that maps each low-dimensional node embedding to one of the 7 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6b00f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (lin1): Linear(in_features=1433, out_features=16, bias=True)\n",
      "  (lin2): Linear(in_features=16, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.lin1 = Linear(dataset.num_features, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin2(x)\n",
    "        return x\n",
    "\n",
    "model = MLP(hidden_channels=16)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d400bc97",
   "metadata": {},
   "source": [
    "Let's train this MLP using the **cross entropy loss** and **Adam optimizer**. A `test` function evaluates how well this model performs on the test-node set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0a4f295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 1.9615\n",
      "Epoch: 002, Loss: 1.9557\n",
      "Epoch: 003, Loss: 1.9505\n",
      "Epoch: 004, Loss: 1.9423\n",
      "Epoch: 005, Loss: 1.9327\n",
      "Epoch: 006, Loss: 1.9279\n",
      "Epoch: 007, Loss: 1.9144\n",
      "Epoch: 008, Loss: 1.9087\n",
      "Epoch: 009, Loss: 1.9023\n",
      "Epoch: 010, Loss: 1.8893\n",
      "Epoch: 011, Loss: 1.8776\n",
      "Epoch: 012, Loss: 1.8594\n",
      "Epoch: 013, Loss: 1.8457\n",
      "Epoch: 014, Loss: 1.8365\n",
      "Epoch: 015, Loss: 1.8280\n",
      "Epoch: 016, Loss: 1.7965\n",
      "Epoch: 017, Loss: 1.7984\n",
      "Epoch: 018, Loss: 1.7832\n",
      "Epoch: 019, Loss: 1.7495\n",
      "Epoch: 020, Loss: 1.7441\n",
      "Epoch: 021, Loss: 1.7188\n",
      "Epoch: 022, Loss: 1.7124\n",
      "Epoch: 023, Loss: 1.6785\n",
      "Epoch: 024, Loss: 1.6660\n",
      "Epoch: 025, Loss: 1.6119\n",
      "Epoch: 026, Loss: 1.6236\n",
      "Epoch: 027, Loss: 1.5827\n",
      "Epoch: 028, Loss: 1.5784\n",
      "Epoch: 029, Loss: 1.5524\n",
      "Epoch: 030, Loss: 1.5020\n",
      "Epoch: 031, Loss: 1.5065\n",
      "Epoch: 032, Loss: 1.4742\n",
      "Epoch: 033, Loss: 1.4581\n",
      "Epoch: 034, Loss: 1.4246\n",
      "Epoch: 035, Loss: 1.4131\n",
      "Epoch: 036, Loss: 1.4112\n",
      "Epoch: 037, Loss: 1.3923\n",
      "Epoch: 038, Loss: 1.3055\n",
      "Epoch: 039, Loss: 1.2982\n",
      "Epoch: 040, Loss: 1.2543\n",
      "Epoch: 041, Loss: 1.2244\n",
      "Epoch: 042, Loss: 1.2331\n",
      "Epoch: 043, Loss: 1.1984\n",
      "Epoch: 044, Loss: 1.1796\n",
      "Epoch: 045, Loss: 1.1093\n",
      "Epoch: 046, Loss: 1.1284\n",
      "Epoch: 047, Loss: 1.1229\n",
      "Epoch: 048, Loss: 1.0383\n",
      "Epoch: 049, Loss: 1.0439\n",
      "Epoch: 050, Loss: 1.0563\n",
      "Epoch: 051, Loss: 0.9893\n",
      "Epoch: 052, Loss: 1.0508\n",
      "Epoch: 053, Loss: 0.9343\n",
      "Epoch: 054, Loss: 0.9639\n",
      "Epoch: 055, Loss: 0.8929\n",
      "Epoch: 056, Loss: 0.8705\n",
      "Epoch: 057, Loss: 0.9176\n",
      "Epoch: 058, Loss: 0.9239\n",
      "Epoch: 059, Loss: 0.8641\n",
      "Epoch: 060, Loss: 0.8578\n",
      "Epoch: 061, Loss: 0.7908\n",
      "Epoch: 062, Loss: 0.7856\n",
      "Epoch: 063, Loss: 0.7683\n",
      "Epoch: 064, Loss: 0.7816\n",
      "Epoch: 065, Loss: 0.7356\n",
      "Epoch: 066, Loss: 0.6951\n",
      "Epoch: 067, Loss: 0.7300\n",
      "Epoch: 068, Loss: 0.6939\n",
      "Epoch: 069, Loss: 0.7550\n",
      "Epoch: 070, Loss: 0.6864\n",
      "Epoch: 071, Loss: 0.7094\n",
      "Epoch: 072, Loss: 0.7238\n",
      "Epoch: 073, Loss: 0.7150\n",
      "Epoch: 074, Loss: 0.6191\n",
      "Epoch: 075, Loss: 0.6770\n",
      "Epoch: 076, Loss: 0.6487\n",
      "Epoch: 077, Loss: 0.6258\n",
      "Epoch: 078, Loss: 0.5821\n",
      "Epoch: 079, Loss: 0.5637\n",
      "Epoch: 080, Loss: 0.6368\n",
      "Epoch: 081, Loss: 0.6333\n",
      "Epoch: 082, Loss: 0.6434\n",
      "Epoch: 083, Loss: 0.5974\n",
      "Epoch: 084, Loss: 0.6176\n",
      "Epoch: 085, Loss: 0.5972\n",
      "Epoch: 086, Loss: 0.4690\n",
      "Epoch: 087, Loss: 0.6362\n",
      "Epoch: 088, Loss: 0.6118\n",
      "Epoch: 089, Loss: 0.5248\n",
      "Epoch: 090, Loss: 0.5520\n",
      "Epoch: 091, Loss: 0.6130\n",
      "Epoch: 092, Loss: 0.5361\n",
      "Epoch: 093, Loss: 0.5594\n",
      "Epoch: 094, Loss: 0.5049\n",
      "Epoch: 095, Loss: 0.5043\n",
      "Epoch: 096, Loss: 0.5235\n",
      "Epoch: 097, Loss: 0.5451\n",
      "Epoch: 098, Loss: 0.5329\n",
      "Epoch: 099, Loss: 0.5008\n",
      "Epoch: 100, Loss: 0.5350\n",
      "Epoch: 101, Loss: 0.5343\n",
      "Epoch: 102, Loss: 0.5138\n",
      "Epoch: 103, Loss: 0.5377\n",
      "Epoch: 104, Loss: 0.5353\n",
      "Epoch: 105, Loss: 0.5176\n",
      "Epoch: 106, Loss: 0.5229\n",
      "Epoch: 107, Loss: 0.4558\n",
      "Epoch: 108, Loss: 0.4883\n",
      "Epoch: 109, Loss: 0.4659\n",
      "Epoch: 110, Loss: 0.4908\n",
      "Epoch: 111, Loss: 0.4966\n",
      "Epoch: 112, Loss: 0.4725\n",
      "Epoch: 113, Loss: 0.4787\n",
      "Epoch: 114, Loss: 0.4390\n",
      "Epoch: 115, Loss: 0.4199\n",
      "Epoch: 116, Loss: 0.4810\n",
      "Epoch: 117, Loss: 0.4484\n",
      "Epoch: 118, Loss: 0.5080\n",
      "Epoch: 119, Loss: 0.4241\n",
      "Epoch: 120, Loss: 0.4745\n",
      "Epoch: 121, Loss: 0.4651\n",
      "Epoch: 122, Loss: 0.4652\n",
      "Epoch: 123, Loss: 0.5580\n",
      "Epoch: 124, Loss: 0.4861\n",
      "Epoch: 125, Loss: 0.4405\n",
      "Epoch: 126, Loss: 0.4292\n",
      "Epoch: 127, Loss: 0.4409\n",
      "Epoch: 128, Loss: 0.3575\n",
      "Epoch: 129, Loss: 0.4468\n",
      "Epoch: 130, Loss: 0.4603\n",
      "Epoch: 131, Loss: 0.4108\n",
      "Epoch: 132, Loss: 0.4601\n",
      "Epoch: 133, Loss: 0.4258\n",
      "Epoch: 134, Loss: 0.3852\n",
      "Epoch: 135, Loss: 0.4028\n",
      "Epoch: 136, Loss: 0.4245\n",
      "Epoch: 137, Loss: 0.4300\n",
      "Epoch: 138, Loss: 0.4693\n",
      "Epoch: 139, Loss: 0.4314\n",
      "Epoch: 140, Loss: 0.4031\n",
      "Epoch: 141, Loss: 0.4290\n",
      "Epoch: 142, Loss: 0.4110\n",
      "Epoch: 143, Loss: 0.3863\n",
      "Epoch: 144, Loss: 0.4215\n",
      "Epoch: 145, Loss: 0.4519\n",
      "Epoch: 146, Loss: 0.3940\n",
      "Epoch: 147, Loss: 0.4429\n",
      "Epoch: 148, Loss: 0.3527\n",
      "Epoch: 149, Loss: 0.4390\n",
      "Epoch: 150, Loss: 0.4212\n",
      "Epoch: 151, Loss: 0.4128\n",
      "Epoch: 152, Loss: 0.3779\n",
      "Epoch: 153, Loss: 0.4801\n",
      "Epoch: 154, Loss: 0.4130\n",
      "Epoch: 155, Loss: 0.3962\n",
      "Epoch: 156, Loss: 0.4262\n",
      "Epoch: 157, Loss: 0.4210\n",
      "Epoch: 158, Loss: 0.4081\n",
      "Epoch: 159, Loss: 0.4066\n",
      "Epoch: 160, Loss: 0.3782\n",
      "Epoch: 161, Loss: 0.3836\n",
      "Epoch: 162, Loss: 0.4172\n",
      "Epoch: 163, Loss: 0.3993\n",
      "Epoch: 164, Loss: 0.4477\n",
      "Epoch: 165, Loss: 0.3714\n",
      "Epoch: 166, Loss: 0.3610\n",
      "Epoch: 167, Loss: 0.4546\n",
      "Epoch: 168, Loss: 0.4387\n",
      "Epoch: 169, Loss: 0.3793\n",
      "Epoch: 170, Loss: 0.3704\n",
      "Epoch: 171, Loss: 0.4286\n",
      "Epoch: 172, Loss: 0.4131\n",
      "Epoch: 173, Loss: 0.3795\n",
      "Epoch: 174, Loss: 0.4230\n",
      "Epoch: 175, Loss: 0.4139\n",
      "Epoch: 176, Loss: 0.3586\n",
      "Epoch: 177, Loss: 0.3588\n",
      "Epoch: 178, Loss: 0.3911\n",
      "Epoch: 179, Loss: 0.3810\n",
      "Epoch: 180, Loss: 0.4203\n",
      "Epoch: 181, Loss: 0.3583\n",
      "Epoch: 182, Loss: 0.3690\n",
      "Epoch: 183, Loss: 0.4025\n",
      "Epoch: 184, Loss: 0.3920\n",
      "Epoch: 185, Loss: 0.4369\n",
      "Epoch: 186, Loss: 0.4317\n",
      "Epoch: 187, Loss: 0.4911\n",
      "Epoch: 188, Loss: 0.3369\n",
      "Epoch: 189, Loss: 0.4945\n",
      "Epoch: 190, Loss: 0.3912\n",
      "Epoch: 191, Loss: 0.3824\n",
      "Epoch: 192, Loss: 0.3479\n",
      "Epoch: 193, Loss: 0.3798\n",
      "Epoch: 194, Loss: 0.3799\n",
      "Epoch: 195, Loss: 0.4015\n",
      "Epoch: 196, Loss: 0.3615\n",
      "Epoch: 197, Loss: 0.3985\n",
      "Epoch: 198, Loss: 0.4664\n",
      "Epoch: 199, Loss: 0.3714\n",
      "Epoch: 200, Loss: 0.3810\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()  # Define loss criterion.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)  # Define optimizer.\n",
    "\n",
    "def train():\n",
    "      model.train()\n",
    "      optimizer.zero_grad()  # Clear gradients.\n",
    "      out = model(graph.x)  # Perform a single forward pass.\n",
    "      loss = criterion(out[graph.train_mask], graph.y[graph.train_mask])  # Compute the loss solely based on the training nodes.\n",
    "      loss.backward()  # Derive gradients.\n",
    "      optimizer.step()  # Update parameters based on gradients.\n",
    "      return loss\n",
    "\n",
    "def test():\n",
    "      model.eval()\n",
    "      out = model(graph.x)\n",
    "      pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "      test_correct = pred[graph.test_mask] == graph.y[graph.test_mask]  # Check against ground-truth labels.\n",
    "      test_acc = int(test_correct.sum()) / int(graph.test_mask.sum())  # Derive ratio of correct predictions.\n",
    "      return test_acc\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    loss = train()\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "c48b496a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.5900\n"
     ]
    }
   ],
   "source": [
    "test_acc = test()\n",
    "print(f'Test Accuracy: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885eb777",
   "metadata": {},
   "source": [
    "As one can see, the MLP performs rather bad with only about 59% test accuracy. But why does the MLP not perform better? The main reason is that this MLP suffers from heavy overfitting due to having access to only a **few training nodes**, and therefore generalizes poorly to unseen node representations.\n",
    "\n",
    "It also fails to incorporate an important bias into the model: **Cited papers are very likely related to the category of a document**. That is exactly where Graph Neural Networks come into play and can help to boost the performance.\n",
    "\n",
    "So, relational information plays a crucial role in obtaining better performance.\n",
    "\n",
    "TO DO:\n",
    "----------\n",
    "1. Print the evolution of weight matrix during the training of GNN. Print all parameters of importance during training of GNN.\n",
    "2. Implement the optional exercise."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
