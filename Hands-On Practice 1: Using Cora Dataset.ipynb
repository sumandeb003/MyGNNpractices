{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20dc944b",
   "metadata": {},
   "source": [
    "# Obtaining the Dataset: Cora\n",
    "\n",
    "PyTorch Geometric is an extension library to the popular deep learning framework PyTorch, and consists of various methods and utilities to ease the implementation of Graph Neural Networks.\n",
    "\n",
    "At first, we need a dataset for training, validating and testing the Graph Neural Network (GNN). We load the Cora dataset (available in PyTorch Geometric framework) in this case. The citation network datasets \"Cora\", \"CiteSeer\" and \"PubMed\" are present in Planetoid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1ebe555e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Cora():\n",
      "======================\n",
      "Number of graphs: 1\n",
      "Number of classes: 7\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('======================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of classes: {dataset.num_classes}')#number of node classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec81f02",
   "metadata": {},
   "source": [
    "PyTorch Geometric provides a **Data** class. An object of the **Data** class is a homogeneous graph. Such an object can hold node-level, link-level and graph-level attributes. \n",
    "\n",
    "In general, **Data** tries to mimic the behavior of a regular Python dictionary. \n",
    "\n",
    "Some of the commonly useful properties of this class and its objects are:\n",
    "1. num_node_features: int\n",
    "2. num_features: int\n",
    "3. num_edge_features: int\n",
    "4. num_node_types: int\n",
    "5. num_edge_types: int\n",
    "6. num_edges: int\n",
    "7. num_nodes: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9ae10cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-th graph\n",
      "------------\n",
      "Number of nodes: 2708\n",
      "Number of node features: 1433\n",
      "Number of edges: 10556\n",
      "Number of edge features: 0\n",
      "Average node degree: 3.90\n",
      "Number of training nodes: 140\n",
      "Number of validation nodes: 500\n",
      "Number of test nodes: 1000\n",
      "Has isolated nodes(nodes without edges): False\n",
      "Has self-loops: False\n",
      "Is undirected: True\n"
     ]
    }
   ],
   "source": [
    "for (i,graph) in zip(range(len(dataset)),dataset):\n",
    "        print(f'{i}-th graph')\n",
    "        print(f'------------')\n",
    "        print(f'Number of nodes: {graph.num_nodes}')\n",
    "        print(f'Number of node features: {graph.num_node_features}')\n",
    "        print(f'Number of edges: {graph.num_edges}')\n",
    "        print(f'Number of edge features: {graph.num_edge_features}')\n",
    "        print(f'Average node degree: {graph.num_edges / graph.num_nodes:.2f}')\n",
    "        print(f'Number of training nodes: {graph.train_mask.sum()}')\n",
    "        print(f'Number of validation nodes: {graph.val_mask.sum()}')\n",
    "        print(f'Number of test nodes: {graph.test_mask.sum()}')\n",
    "        print(f'Has isolated nodes(nodes without edges): {graph.has_isolated_nodes()}')\n",
    "        print(f'Has self-loops: {graph.has_self_loops()}')\n",
    "        print(f'Is undirected: {graph.is_undirected()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c4a72be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 4,  ..., 3, 3, 3])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].y #contains the ground-truth label of each of the 2708 nodes in the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "cc815e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2708"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[0].y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f7eed108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "len(np.unique(np.array(dataset[0].y)))#np.unique() is a utility from the numpy library that removes duplicates in a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ecd403b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].x #a tensor containing the node embeddings. Each embedding corresponds to one of the 7 ground-truth labels of the nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9495be75",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2708"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[0].x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1a20a8ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 1.,  ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].x[2700] #embeddings of the 2701th node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e97a6a",
   "metadata": {},
   "source": [
    "By printing '**edge_index**', we can understand how PyG represents graph connectivity internally. We can see that for each edge, edge_index holds a tuple of two node indices, where the first value describes the node index of the source node and the second value describes the node index of the destination node of an edge.\n",
    "\n",
    "This representation is known as the **COO format** (co-ordinate format) commonly used for representing sparse matrices. Instead of holding the adjacency information in a dense representation, PyG represents graphs sparsely, which refers to only holding the coordinates/values for which entries are non-zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc3f81b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,    0,    0,  ..., 2707, 2707, 2707],\n",
       "        [ 633, 1862, 2582,  ...,  598, 1473, 2706]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d818c5ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[0].edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "33743efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,  633],\n",
       "        [   0, 1862],\n",
       "        [   0, 2582],\n",
       "        ...,\n",
       "        [2707,  598],\n",
       "        [2707, 1473],\n",
       "        [2707, 2706]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.transpose(dataset[0].edge_index,0,1) #shows the source and the destination nodes of each edge in the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "733d96b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0].edge_attr #Edge feature matrix (default: None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ecbb267f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0].pos #Node position matrix (default: None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f558f1",
   "metadata": {},
   "source": [
    "## Implementing a Graph Neural Network (GNN)\n",
    "\n",
    "In the following cell, we implement a 2-layered GNN. Each layer performs the following graph convolution operation ([Kipf et al. (2017)](https://arxiv.org/abs/1609.02907)):\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_v^{(\\ell + 1)} = \\mathbf{W}^{(\\ell + 1)} \\sum_{w \\in \\mathcal{N}(v) \\, \\cup \\, \\{ v \\}} \\frac{1}{c_{w,v}} \\cdot \\mathbf{x}_w^{(\\ell)}\n",
    "$$\n",
    "\n",
    "where, $\\mathbf{W}^{(\\ell + 1)}$ denotes a trainable weight matrix of shape `[num_output_features, num_input_features]` and $c_{w,v}$ refers to a fixed normalization coefficient for each edge.\n",
    "\n",
    "PyG implements this layer via its [`GCNConv`](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GCNConv) class, specifically the `forward` function in it. It is executed by passing in the node-feature representation `x` and the COO graph-connectivity representation `edge_index`.\n",
    "\n",
    "The Graph Neural Network (GNN) architecture is described in a child class `GCN` derived from the `torch.nn.Module` class of PyTorch. The `GCN` class contains the dimensions of individual convolution layers and the sequence of the convolution layers and non-linear activations (that follow each of the convolution layers). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f5f8e403",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GCN(torch.nn.Module):#torch.nn.Module is the base class for all neural network modules in PyTorch \n",
    "    def __init__(self):#defines the layers of the GNN and initializes them\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)#GCNConv() performs message computation, aggregation of the messages, and then, updating of the node embeddings. The 1st parameter 'number of input features per node' and the 2nd argument 'number of features per output' are provided for initializing the parameters of the class GCNConv.\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):#defines the computation flow of our network\n",
    "        x, edge_index = data.x, data.edge_index#'x' represents the vector of node features and edge_index represents the adjacency matrix for connectivity\n",
    "\n",
    "        x = self.conv1(x, edge_index)#conv1.forward() gets called here. The arguments 'x' and 'edge_index' are passed as inputs to forward().\n",
    "        x = F.relu(x)#Applying Relu activation on the result of the above graph-convolution operation.\n",
    "        \n",
    "        x = F.dropout(x, training=self.training)#Randomly zero some of the elements of the input tensor 'x' with probability p(default: 0.5) using samples from a Bernoulli distribution.Also, the mode is set to 'training' because Dropout behaves differently during training and testing.\n",
    "        \n",
    "        x = self.conv2(x, edge_index)#conv2.forward() gets called here. The arguments 'x' and 'edge_index' are passed as inputs to forward().\n",
    "        return F.log_softmax(x, dim=1)#Applying softmax activation on the result of the above graph-convolution operation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f87f765",
   "metadata": {},
   "source": [
    "Then, we choose the device on which we want to deploy the GNN and the training dataset.\n",
    "\n",
    "A **torch.device** is an object representing the device on which a torch.Tensor is or will be allocated. The torch.device contains a device type ('cpu', 'cuda' or 'mps') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7104f29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172f14a3",
   "metadata": {},
   "source": [
    "Next, we move the GNN parameters to the chosen device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a9c47798",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615e2f99",
   "metadata": {},
   "source": [
    "Also, we move the dataset to the chosen device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cf8a9dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset[0].to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd3ae1b",
   "metadata": {},
   "source": [
    "## Training the GNN\n",
    "\n",
    "Then, we choose the optimization algorithm (from the *torch.optim* package) for training/optimizing the parameters of our GNN. As an input, we provided *model.parameters()* to denote which parameters (tensors) to optimize. We also defined the decay constant and learning rate (lr).\n",
    "\n",
    "**NOTE:** During training, the weights (parameters) of the GNN are learnt and not the embeddings of the nodes. The GNN just predicts or computes the embeddings of the nodes using *neural message passing*. The GNN just maps the input node-embeddings to new embeddings. So, the GNN can be seen as graph transformer, *i.e.*, it transforms the input graph into output graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0fc05fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453ed991",
   "metadata": {},
   "source": [
    "Next, we set the mode of GCN module (torch.nn.Module) to training. '*model.train()*' simple changes the '*self.training*' flag via '*self.training = training*' recursively for all modules. \n",
    "\n",
    "**Note**: By default, the mode is set to training and that is why they omit '*model.train()*' call. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "087ebc64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (conv1): GCNConv(1433, 16)\n",
       "  (conv2): GCNConv(16, 7)\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c309fd44",
   "metadata": {},
   "source": [
    "We train the GCN module for 200 epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f0f57cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()#Initializes the gradients to zero at the beginning of each epoch\n",
    "    out = model(data)#Calls the 'forward' method in the class GCN and stores the output/prediction of the network.\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])#Calculates the negative log likelihood loss (nll) between original ('data.y') and predicted data ('out') points\n",
    "    loss.backward()#Backward pass for computing the gradients of the loss w.r.t to learnable parameters\n",
    "    optimizer.step()#Updates the learnt parameters at the end of each epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb6560c",
   "metadata": {},
   "source": [
    "**Final node-embeddings computed by the trained GNN:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4e61fad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-7.5913e+00, -9.7466e+00, -8.1143e+00,  ..., -7.7475e+00,\n",
       "         -8.4288e+00, -7.6125e+00],\n",
       "        [-1.0887e+01, -1.3381e+01, -1.6949e+01,  ..., -2.5868e-05,\n",
       "         -1.3200e+01, -1.2966e+01],\n",
       "        [-8.3471e+00, -1.0761e+01, -1.2356e+01,  ..., -8.2685e-04,\n",
       "         -1.0384e+01, -1.0233e+01],\n",
       "        ...,\n",
       "        [-1.8628e+00, -1.1648e+00, -6.6731e+00,  ..., -5.1301e+00,\n",
       "         -8.1067e-01, -2.7729e+00],\n",
       "        [-6.0501e+00, -7.4291e+00, -6.4877e+00,  ..., -5.0024e+00,\n",
       "         -6.2770e+00, -7.9431e+00],\n",
       "        [-5.6314e+00, -6.7476e+00, -5.7861e+00,  ..., -4.9334e+00,\n",
       "         -5.6416e+00, -7.4269e+00]], device='cuda:0',\n",
       "       grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(data) #model(data) is the tensor containing the node embeddings computed by the GNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38027baf",
   "metadata": {},
   "source": [
    "## Testing the trained GNN\n",
    "\n",
    "Next, we set the mode of GCN module (torch.nn.Module) to testing. This is equivalent to executing: ***model.train(mode=False)***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "01118dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (conv1): GCNConv(1433, 16)\n",
       "  (conv2): GCNConv(16, 7)\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "86042a90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-7.5913e+00, -9.7466e+00, -8.1143e+00, -2.0090e-03, -7.7475e+00,\n",
       "        -8.4288e+00, -7.6125e+00], device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(data)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b2c9eb3b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3, device='cuda:0')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(data)[0].argmax(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9fccc056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.0887e+01, -1.3381e+01, -1.6949e+01, -1.3455e+01, -2.5868e-05,\n",
       "        -1.3200e+01, -1.2966e+01], device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(data)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8daf14ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4, device='cuda:0')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(data)[1].argmax(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6db4094c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-7.5913e+00, -9.7466e+00, -8.1143e+00, -2.0090e-03, -7.7475e+00,\n",
       "         -8.4288e+00, -7.6125e+00],\n",
       "        [-1.0887e+01, -1.3381e+01, -1.6949e+01, -1.3455e+01, -2.5868e-05,\n",
       "         -1.3200e+01, -1.2966e+01]], device='cuda:0', grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(data)[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "36941dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 1, 0, 0], device='cuda:0')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(data)[0:2].argmax(dim=0) #dim 0 => along each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2083ffae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4], device='cuda:0')"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(data)[0:2].argmax(dim=1) #dim 1 =>along each row (feature vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5e9879",
   "metadata": {},
   "source": [
    "Obtain the predicted label by storing the label corresponding to the node embedding that has max probability. Note that, as mentioned above, each of the 7 embeddings of a node corresponds to one of the 7 labels possible for a node. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ef80d57c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 4,  ..., 5, 3, 3], device='cuda:0')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model(data).argmax(dim=1)\n",
    "pred #tensor containing list of indices of the largest features of each node in the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0d69f844",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2708"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8bca46d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False,  ...,  True,  True,  True], device='cuda:0')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.test_mask #tensor that labels each of the 2708 nodes of the graph as a test sample or non-test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "247963c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2708"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.test_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7eee6715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2,\n",
       "        2, 1, 2, 1, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 5, 5, 4, 4, 4, 1, 1, 3, 0, 1, 1, 6,\n",
       "        2, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5,\n",
       "        5, 5, 2, 2, 2, 2, 2, 6, 6, 3, 0, 0, 0, 0, 5, 0, 0, 0, 3, 0, 0, 6, 0, 6,\n",
       "        3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 5, 5, 5, 5, 5, 5, 5, 5, 2, 2, 2, 4, 4, 4, 4, 4, 3, 2, 5, 5, 5, 5,\n",
       "        6, 5, 5, 5, 5, 6, 4, 4, 0, 3, 1, 0, 0, 0, 6, 6, 6, 6, 6, 6, 6, 0, 0, 0,\n",
       "        0, 0, 0, 0, 3, 4, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        6, 6, 5, 6, 6, 0, 5, 5, 5, 0, 5, 4, 4, 4, 3, 3, 3, 3, 3, 1, 3, 3, 3, 6,\n",
       "        3, 3, 1, 3, 3, 4, 4, 4, 3, 3, 3, 3, 3, 3, 6, 3, 0, 0, 0, 0, 6, 5, 5, 5,\n",
       "        4, 0, 6, 6, 5, 5, 1, 3, 5, 5, 6, 6, 4, 4, 4, 4, 3, 3, 4, 4, 4, 3, 4, 4,\n",
       "        4, 1, 1, 1, 1, 0, 6, 0, 0, 0, 0, 0, 0, 0, 2, 0, 5, 5, 5, 3, 3, 3, 3, 3,\n",
       "        0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 3,\n",
       "        1, 1, 1, 1, 1, 0, 0, 0, 6, 6, 0, 0, 0, 0, 1, 1, 0, 6, 6, 6, 6, 2, 3, 3,\n",
       "        0, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 3, 4, 0, 6, 0, 6, 6, 0, 0, 3, 3,\n",
       "        3, 3, 3, 1, 1, 1, 3, 3, 3, 3, 2, 6, 3, 5, 6, 0, 5, 6, 6, 6, 6, 6, 3, 3,\n",
       "        6, 6, 6, 1, 2, 1, 5, 0, 0, 5, 5, 3, 3, 0, 5, 0, 0, 0, 0, 0, 5, 5, 0, 4,\n",
       "        0, 6, 6, 4, 6, 0, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 1, 6, 1, 0,\n",
       "        3, 3, 3, 3, 3, 6, 1, 0, 2, 2, 4, 4, 4, 4, 4, 5, 6, 3, 3, 0, 0, 0, 0, 5,\n",
       "        4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 1, 1, 4, 1, 6, 1, 3, 3, 4,\n",
       "        4, 4, 4, 0, 4, 4, 0, 0, 3, 5, 5, 5, 5, 5, 0, 5, 0, 0, 6, 2, 0, 5, 6, 3,\n",
       "        5, 5, 5, 5, 5, 4, 4, 4, 4, 6, 4, 4, 3, 0, 0, 4, 1, 3, 4, 3, 3, 3, 3, 2,\n",
       "        3, 3, 3, 0, 0, 1, 1, 3, 3, 3, 1, 0, 0, 0, 1, 5, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "        4, 0, 2, 4, 4, 4, 3, 3, 3, 3, 5, 3, 3, 4, 4, 0, 4, 4, 4, 3, 4, 3, 3, 0,\n",
       "        0, 0, 4, 2, 3, 3, 4, 5, 0, 2, 2, 3, 3, 3, 3, 3, 3, 0, 5, 5, 4, 1, 4, 4,\n",
       "        4, 4, 4, 4, 0, 3, 4, 4, 6, 2, 2, 2, 2, 4, 6, 6, 6, 0, 3, 4, 4, 4, 3, 3,\n",
       "        0, 5, 3, 5, 0, 0, 3, 3, 3, 3, 3, 2, 4, 4, 3, 0, 3, 2, 6, 0, 0, 0, 3, 5,\n",
       "        5, 1, 3, 4, 4, 5, 4, 4, 6, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2,\n",
       "        2, 0, 6, 6, 2, 6, 6, 3, 2, 6, 3, 4, 4, 4, 2, 5, 5, 2, 2, 3, 0, 4, 4, 3,\n",
       "        2, 3, 1, 6, 6, 5, 0, 4, 4, 6, 3, 1, 1, 3, 0, 5, 2, 3, 3, 3, 4, 5, 5, 0,\n",
       "        3, 3, 0, 2, 1, 1, 5, 2, 3, 3, 1, 0, 2, 3, 2, 2, 5, 5, 4, 3, 4, 3, 2, 2,\n",
       "        4, 2, 4, 5, 5, 3, 2, 3, 3, 0, 3, 3, 4, 5, 4, 3, 3, 3, 1, 3, 0, 0, 2, 4,\n",
       "        4, 4, 3, 3, 3, 5, 2, 3, 2, 2, 2, 3, 2, 2, 6, 4, 4, 0, 3, 0, 3, 4, 3, 3,\n",
       "        3, 6, 3, 0, 0, 3, 3, 3, 3, 2, 3, 4, 2, 2, 6, 4, 3, 3, 4, 1, 5, 3, 4, 3,\n",
       "        2, 2, 1, 3, 0, 3, 2, 2, 6, 3, 2, 2, 6, 1, 3, 0, 2, 3, 2, 4, 2, 5, 3, 3,\n",
       "        0, 5, 6, 0, 3, 3, 3, 2, 5, 3, 5, 4, 3, 3, 3, 3, 3, 4, 6, 6, 5, 2, 2, 2,\n",
       "        0, 4, 4, 4, 4, 6, 3, 2, 2, 6, 2, 0, 2, 2, 2, 3, 4, 4, 4, 3, 0, 4, 4, 3,\n",
       "        3, 0, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 0, 4, 2, 3, 3, 3, 2, 3, 2,\n",
       "        6, 3, 4, 4, 4, 3, 3, 5, 3, 3, 3, 3, 2, 5, 3, 3], device='cuda:0')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[data.test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c57ec94f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred[data.test_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d6191488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2acd10d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 4,  ..., 3, 3, 3], device='cuda:0')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9cb82a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2708"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e5bf86c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2,\n",
       "        2, 2, 2, 1, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 5, 2, 2, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 3, 4, 4, 4, 4, 1, 1, 3, 1, 0, 3, 0,\n",
       "        2, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5,\n",
       "        5, 5, 2, 2, 2, 2, 1, 6, 6, 3, 0, 0, 5, 0, 5, 0, 3, 5, 3, 0, 0, 6, 0, 6,\n",
       "        3, 3, 1, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 5, 5, 5, 5, 5, 5, 5, 5, 2, 2, 2, 4, 4, 4, 0, 3, 3, 2, 5, 5, 5, 5,\n",
       "        6, 5, 5, 5, 5, 0, 4, 4, 4, 0, 0, 5, 0, 0, 6, 6, 6, 6, 6, 6, 0, 0, 0, 0,\n",
       "        3, 0, 0, 0, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 5, 5, 5, 5, 3, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        6, 6, 5, 6, 6, 3, 5, 5, 5, 0, 5, 0, 4, 4, 3, 3, 3, 2, 2, 1, 3, 3, 3, 3,\n",
       "        3, 3, 5, 3, 3, 4, 4, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 6, 3, 6, 0, 5, 0, 0,\n",
       "        4, 0, 6, 5, 5, 0, 1, 3, 3, 5, 6, 5, 3, 3, 4, 3, 3, 3, 3, 3, 4, 3, 3, 4,\n",
       "        3, 1, 1, 0, 1, 0, 6, 0, 0, 0, 0, 0, 0, 0, 5, 0, 5, 5, 5, 3, 3, 3, 3, 3,\n",
       "        0, 0, 0, 2, 0, 0, 0, 3, 3, 3, 3, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 0, 1, 3,\n",
       "        1, 1, 1, 1, 1, 0, 0, 0, 5, 5, 5, 5, 3, 5, 1, 1, 3, 6, 6, 5, 6, 2, 3, 3,\n",
       "        0, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 4, 3, 3, 4, 0, 6, 0, 6, 6, 0, 0, 3, 3,\n",
       "        3, 3, 3, 1, 1, 1, 3, 3, 3, 3, 5, 6, 3, 4, 6, 0, 0, 6, 6, 6, 6, 6, 3, 3,\n",
       "        6, 6, 5, 2, 1, 2, 1, 0, 0, 6, 6, 2, 3, 3, 5, 0, 0, 0, 0, 0, 5, 5, 0, 3,\n",
       "        5, 0, 6, 3, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 1, 6, 1, 0,\n",
       "        3, 3, 3, 3, 3, 6, 1, 0, 2, 2, 4, 4, 4, 4, 4, 5, 6, 3, 3, 0, 0, 0, 0, 5,\n",
       "        4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 0, 3, 4, 4, 4, 1, 1, 3, 1, 1, 5, 1, 3, 4,\n",
       "        4, 4, 4, 4, 4, 4, 0, 0, 0, 5, 5, 5, 5, 5, 0, 5, 3, 0, 6, 2, 0, 5, 3, 3,\n",
       "        5, 5, 5, 5, 5, 4, 4, 0, 4, 0, 4, 0, 3, 4, 4, 4, 1, 3, 3, 3, 3, 3, 4, 2,\n",
       "        3, 3, 3, 0, 0, 2, 3, 3, 3, 3, 1, 1, 3, 0, 1, 4, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "        0, 0, 2, 4, 4, 4, 3, 3, 3, 4, 0, 3, 3, 3, 3, 0, 3, 3, 4, 4, 4, 4, 4, 4,\n",
       "        0, 4, 3, 2, 0, 3, 4, 5, 0, 2, 2, 3, 3, 3, 3, 3, 2, 3, 5, 5, 4, 1, 4, 4,\n",
       "        4, 3, 4, 4, 0, 4, 4, 4, 5, 2, 2, 2, 2, 4, 6, 6, 6, 6, 3, 4, 4, 4, 1, 3,\n",
       "        0, 3, 3, 5, 0, 2, 3, 3, 3, 3, 3, 2, 4, 4, 0, 0, 3, 2, 6, 6, 0, 3, 3, 3,\n",
       "        5, 1, 3, 4, 4, 2, 4, 4, 4, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2,\n",
       "        2, 0, 6, 6, 5, 6, 6, 3, 2, 6, 3, 4, 4, 4, 2, 6, 6, 0, 0, 3, 0, 4, 4, 3,\n",
       "        2, 3, 1, 6, 6, 5, 3, 4, 3, 5, 3, 1, 1, 3, 4, 5, 2, 3, 3, 3, 4, 5, 4, 0,\n",
       "        3, 3, 0, 2, 1, 1, 5, 2, 3, 3, 5, 0, 2, 3, 2, 2, 5, 5, 4, 3, 4, 3, 2, 2,\n",
       "        4, 2, 4, 5, 5, 3, 2, 3, 1, 0, 3, 3, 4, 5, 4, 3, 3, 3, 3, 3, 0, 1, 2, 4,\n",
       "        4, 4, 3, 3, 3, 5, 2, 3, 2, 2, 2, 3, 2, 2, 0, 4, 4, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 0, 0, 3, 0, 3, 0, 2, 3, 4, 1, 2, 5, 4, 3, 3, 3, 1, 5, 3, 4, 3,\n",
       "        2, 2, 1, 3, 3, 3, 3, 3, 6, 3, 3, 3, 6, 3, 3, 3, 2, 3, 2, 4, 2, 4, 2, 2,\n",
       "        1, 5, 6, 4, 3, 3, 3, 2, 5, 3, 3, 4, 3, 3, 3, 3, 3, 4, 6, 0, 3, 2, 2, 2,\n",
       "        5, 4, 4, 4, 4, 6, 3, 2, 2, 0, 2, 2, 2, 2, 2, 3, 4, 4, 4, 3, 3, 4, 4, 3,\n",
       "        3, 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 2, 3, 3, 3, 2, 6, 2,\n",
       "        3, 3, 4, 4, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3], device='cuda:0')"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y[data.test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d8259ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.y[data.test_mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe00cc6d",
   "metadata": {},
   "source": [
    "Compute the total number of correct predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e77415d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(807, device='cuda:0')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035bbaba",
   "metadata": {},
   "source": [
    "Finally, we compute and print the accuracy performance of the GNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "26a96a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8070\n"
     ]
    }
   ],
   "source": [
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
