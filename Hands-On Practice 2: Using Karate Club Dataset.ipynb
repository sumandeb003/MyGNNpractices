{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c848b08",
   "metadata": {},
   "source": [
    "# Obtaining the Dataset: Karate Club\n",
    "\n",
    "PyTorch Geometric is an extension library to the popular deep learning framework PyTorch, and consists of various methods and utilities to ease the implementation of Graph Neural Networks.\n",
    "\n",
    "At first, we need a dataset for training, validating and testing the Graph Neural Network (GNN). In this hands-on practice, I will use the well-known Zachary's karate club dataset. This graph describes a social network of **34 members** of a karate club and documents links between members who interacted outside the club. The task is to detect communities that arise from the member's interaction.\n",
    "\n",
    "**Dataset details:**\n",
    "**\n",
    "\n",
    "PyTorch Geometric provides an easy access to this dataset via the **torch_geometric.datasets** subpackage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ae703e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: KarateClub():\n",
      "======================\n",
      "Number of graphs in the dataset: 1\n",
      "Number of classes: 4\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import KarateClub\n",
    "\n",
    "\n",
    "dataset = KarateClub()#stores the entire dataset - with all the graphs\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('======================')\n",
    "print(f'Number of graphs in the dataset: {len(dataset)}')\n",
    "print(f'Number of classes: {dataset.num_classes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fc4232",
   "metadata": {},
   "source": [
    "PyTorch Geometric provides a **Data** class. An object of the **Data** class is a homogeneous graph. Such an object can hold node-level, link-level and graph-level attributes. \n",
    "\n",
    "In general, **Data** tries to mimic the behavior of a regular Python dictionary. \n",
    "\n",
    "Some of the commonly useful properties of this class and its objects are:\n",
    "1. **num_node_features**: int\n",
    "2. **num_nodes**: int\n",
    "3. **num_edge_features**: int\n",
    "4. **num_edges**: int\n",
    "5. **num_classes**: int\n",
    "6. num_edge_types: int\n",
    "7. num_node_types: int\n",
    "\n",
    "Some of the useful methods of this class and its objects are:\n",
    "1. .is_undirected()\n",
    "2. .has_self_loops()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d1fae7aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-th graph: Data(x=[34, 34], edge_index=[2, 156], y=[34], train_mask=[34])\n",
      "------------\n",
      "Number of nodes: 34\n",
      "Number of node features: 34\n",
      "Number of edges: 156\n",
      "Number of edge features: 0\n",
      "Average node degree: 4.59\n",
      "Number of training nodes: 4\n",
      "Has isolated nodes(nodes without edges): False\n",
      "Has self-loops: False\n",
      "Is undirected: True\n"
     ]
    }
   ],
   "source": [
    "for (i,graph) in zip(range(len(dataset)),dataset):\n",
    "        print(f'{i}-th graph: {graph}')\n",
    "        print(f'------------')\n",
    "        print(f'Number of nodes: {graph.num_nodes}')\n",
    "        print(f'Number of node features: {graph.num_node_features}')\n",
    "        print(f'Number of edges: {graph.num_edges}')\n",
    "        print(f'Number of edge features: {graph.num_edge_features}')\n",
    "        print(f'Average node degree: {graph.num_edges / graph.num_nodes:.2f}')\n",
    "        print(f'Number of training nodes: {graph.train_mask.sum()}')\n",
    "        print(f'Has isolated nodes(nodes without edges): {graph.has_isolated_nodes()}')\n",
    "        print(f'Has self-loops: {graph.has_self_loops()}')\n",
    "        print(f'Is undirected: {graph.is_undirected()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96752293",
   "metadata": {},
   "source": [
    "So, only 4 nodes are labeled. Labels of rest of the nodes are to be inferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f4c7307f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 3, 3, 3, 1, 0, 1, 3, 1, 1, 1, 0, 0, 3, 1, 0, 1, 0, 1, 0, 0,\n",
       "        2, 2, 0, 0, 2, 0, 0, 2, 0, 0])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].y #ground-truth label of all the nodes in the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "66ab0787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[0].y) #number of labels = number of nodes in the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f307d253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "len(np.unique(np.array(dataset[0].y)))#np.unique() is a utility from the numpy library that removes duplicates in a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "14ff8446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].x #feature vector of all the nodes in this graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cf962ab2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[0].x) #number of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2b5fea79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].x[33] #feature vector of 34th node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "529be80b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[0].x[33])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b63cd53",
   "metadata": {},
   "source": [
    "By printing '**edge_index**', we can understand how PyG represents graph connectivity internally. We can see that for each edge, edge_index holds a tuple of two node indices, where the first value describes the node index of the source node and the second value describes the node index of the destination node of an edge.\n",
    "\n",
    "This representation is known as the **COO format** (co-ordinate format) commonly used for representing sparse matrices. Instead of holding the adjacency information in a dense representation, PyG represents graphs sparsely, which refers to only holding the coordinates/values for which entries are non-zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8aea53e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,\n",
       "          1,  1,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  3,\n",
       "          3,  3,  3,  3,  3,  4,  4,  4,  5,  5,  5,  5,  6,  6,  6,  6,  7,  7,\n",
       "          7,  7,  8,  8,  8,  8,  8,  9,  9, 10, 10, 10, 11, 12, 12, 13, 13, 13,\n",
       "         13, 13, 14, 14, 15, 15, 16, 16, 17, 17, 18, 18, 19, 19, 19, 20, 20, 21,\n",
       "         21, 22, 22, 23, 23, 23, 23, 23, 24, 24, 24, 25, 25, 25, 26, 26, 27, 27,\n",
       "         27, 27, 28, 28, 28, 29, 29, 29, 29, 30, 30, 30, 30, 31, 31, 31, 31, 31,\n",
       "         31, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 33, 33, 33, 33, 33,\n",
       "         33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33],\n",
       "        [ 1,  2,  3,  4,  5,  6,  7,  8, 10, 11, 12, 13, 17, 19, 21, 31,  0,  2,\n",
       "          3,  7, 13, 17, 19, 21, 30,  0,  1,  3,  7,  8,  9, 13, 27, 28, 32,  0,\n",
       "          1,  2,  7, 12, 13,  0,  6, 10,  0,  6, 10, 16,  0,  4,  5, 16,  0,  1,\n",
       "          2,  3,  0,  2, 30, 32, 33,  2, 33,  0,  4,  5,  0,  0,  3,  0,  1,  2,\n",
       "          3, 33, 32, 33, 32, 33,  5,  6,  0,  1, 32, 33,  0,  1, 33, 32, 33,  0,\n",
       "          1, 32, 33, 25, 27, 29, 32, 33, 25, 27, 31, 23, 24, 31, 29, 33,  2, 23,\n",
       "         24, 33,  2, 31, 33, 23, 26, 32, 33,  1,  8, 32, 33,  0, 24, 25, 28, 32,\n",
       "         33,  2,  8, 14, 15, 18, 20, 22, 23, 29, 30, 31, 33,  8,  9, 13, 14, 15,\n",
       "         18, 19, 20, 22, 23, 26, 27, 28, 29, 30, 31, 32]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].edge_index #node-connectivity representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "929ddfbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[0].edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0e768b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1],\n",
       "        [ 0,  2],\n",
       "        [ 0,  3],\n",
       "        [ 0,  4],\n",
       "        [ 0,  5],\n",
       "        [ 0,  6],\n",
       "        [ 0,  7],\n",
       "        [ 0,  8],\n",
       "        [ 0, 10],\n",
       "        [ 0, 11],\n",
       "        [ 0, 12],\n",
       "        [ 0, 13],\n",
       "        [ 0, 17],\n",
       "        [ 0, 19],\n",
       "        [ 0, 21],\n",
       "        [ 0, 31],\n",
       "        [ 1,  0],\n",
       "        [ 1,  2],\n",
       "        [ 1,  3],\n",
       "        [ 1,  7],\n",
       "        [ 1, 13],\n",
       "        [ 1, 17],\n",
       "        [ 1, 19],\n",
       "        [ 1, 21],\n",
       "        [ 1, 30],\n",
       "        [ 2,  0],\n",
       "        [ 2,  1],\n",
       "        [ 2,  3],\n",
       "        [ 2,  7],\n",
       "        [ 2,  8],\n",
       "        [ 2,  9],\n",
       "        [ 2, 13],\n",
       "        [ 2, 27],\n",
       "        [ 2, 28],\n",
       "        [ 2, 32],\n",
       "        [ 3,  0],\n",
       "        [ 3,  1],\n",
       "        [ 3,  2],\n",
       "        [ 3,  7],\n",
       "        [ 3, 12],\n",
       "        [ 3, 13],\n",
       "        [ 4,  0],\n",
       "        [ 4,  6],\n",
       "        [ 4, 10],\n",
       "        [ 5,  0],\n",
       "        [ 5,  6],\n",
       "        [ 5, 10],\n",
       "        [ 5, 16],\n",
       "        [ 6,  0],\n",
       "        [ 6,  4],\n",
       "        [ 6,  5],\n",
       "        [ 6, 16],\n",
       "        [ 7,  0],\n",
       "        [ 7,  1],\n",
       "        [ 7,  2],\n",
       "        [ 7,  3],\n",
       "        [ 8,  0],\n",
       "        [ 8,  2],\n",
       "        [ 8, 30],\n",
       "        [ 8, 32],\n",
       "        [ 8, 33],\n",
       "        [ 9,  2],\n",
       "        [ 9, 33],\n",
       "        [10,  0],\n",
       "        [10,  4],\n",
       "        [10,  5],\n",
       "        [11,  0],\n",
       "        [12,  0],\n",
       "        [12,  3],\n",
       "        [13,  0],\n",
       "        [13,  1],\n",
       "        [13,  2],\n",
       "        [13,  3],\n",
       "        [13, 33],\n",
       "        [14, 32],\n",
       "        [14, 33],\n",
       "        [15, 32],\n",
       "        [15, 33],\n",
       "        [16,  5],\n",
       "        [16,  6],\n",
       "        [17,  0],\n",
       "        [17,  1],\n",
       "        [18, 32],\n",
       "        [18, 33],\n",
       "        [19,  0],\n",
       "        [19,  1],\n",
       "        [19, 33],\n",
       "        [20, 32],\n",
       "        [20, 33],\n",
       "        [21,  0],\n",
       "        [21,  1],\n",
       "        [22, 32],\n",
       "        [22, 33],\n",
       "        [23, 25],\n",
       "        [23, 27],\n",
       "        [23, 29],\n",
       "        [23, 32],\n",
       "        [23, 33],\n",
       "        [24, 25],\n",
       "        [24, 27],\n",
       "        [24, 31],\n",
       "        [25, 23],\n",
       "        [25, 24],\n",
       "        [25, 31],\n",
       "        [26, 29],\n",
       "        [26, 33],\n",
       "        [27,  2],\n",
       "        [27, 23],\n",
       "        [27, 24],\n",
       "        [27, 33],\n",
       "        [28,  2],\n",
       "        [28, 31],\n",
       "        [28, 33],\n",
       "        [29, 23],\n",
       "        [29, 26],\n",
       "        [29, 32],\n",
       "        [29, 33],\n",
       "        [30,  1],\n",
       "        [30,  8],\n",
       "        [30, 32],\n",
       "        [30, 33],\n",
       "        [31,  0],\n",
       "        [31, 24],\n",
       "        [31, 25],\n",
       "        [31, 28],\n",
       "        [31, 32],\n",
       "        [31, 33],\n",
       "        [32,  2],\n",
       "        [32,  8],\n",
       "        [32, 14],\n",
       "        [32, 15],\n",
       "        [32, 18],\n",
       "        [32, 20],\n",
       "        [32, 22],\n",
       "        [32, 23],\n",
       "        [32, 29],\n",
       "        [32, 30],\n",
       "        [32, 31],\n",
       "        [32, 33],\n",
       "        [33,  8],\n",
       "        [33,  9],\n",
       "        [33, 13],\n",
       "        [33, 14],\n",
       "        [33, 15],\n",
       "        [33, 18],\n",
       "        [33, 19],\n",
       "        [33, 20],\n",
       "        [33, 22],\n",
       "        [33, 23],\n",
       "        [33, 26],\n",
       "        [33, 27],\n",
       "        [33, 28],\n",
       "        [33, 29],\n",
       "        [33, 30],\n",
       "        [33, 31],\n",
       "        [33, 32]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.transpose(dataset[0].edge_index,0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d566f31",
   "metadata": {},
   "source": [
    "By printing '**edge_index**', we can understand how PyG represents graph connectivity internally. We can see that for each edge, edge_index holds a tuple of two node indices, where the first value describes the node index of the source node and the second value describes the node index of the destination node of an edge.\n",
    "\n",
    "This representation is known as the **COO format** (co-ordinate format) commonly used for representing sparse matrices. Instead of holding the adjacency information in a dense representation, PyG represents graphs sparsely, which refers to only holding the coordinates/values for which entries are non-zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "006f2eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0].edge_attr #Edge feature matrix (default: None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "db0073fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0].pos #Node position matrix (default: None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566bbfdd",
   "metadata": {},
   "source": [
    "## Implementing a Graph Neural Network (GNN)\n",
    "\n",
    "Next, we implement a 3-layered GNN. Each layer performs the following graph convolution operation ([Kipf et al. (2017)](https://arxiv.org/abs/1609.02907)):\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_v^{(\\ell + 1)} = \\mathbf{W}^{(\\ell + 1)} \\sum_{w \\in \\mathcal{N}(v) \\, \\cup \\, \\{ v \\}} \\frac{1}{c_{w,v}} \\cdot \\mathbf{x}_w^{(\\ell)}\n",
    "$$\n",
    "\n",
    "where, $\\mathbf{W}^{(\\ell + 1)}$ denotes a **trainable weight matrix** of shape `[num_output_features, num_input_features]` and $c_{w,v}$ refers to a fixed normalization coefficient for each edge.\n",
    "\n",
    "PyG implements this layer via its [`GCNConv`](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GCNConv) class, specifically the `forward` function in it. It is executed by passing in the node-feature representation `x` and the COO graph-connectivity representation `edge_index`.\n",
    "\n",
    "The Graph Neural Network (GNN) architecture is described in a child class `GCN` derived from the `torch.nn.Module` class of PyTorch. The `GCN` class initializes the architecture of the network in `__init__` and defines the computation flow of the network in `forward`. The network has three graph convolution layers, which corresponds to aggregating 3-hop neighborhood information around each node (all nodes up to 3 \"hops\" away). In addition, the GCNConv layers reduce the node feature dimensionality to  $2$ , *i.e.*,  $34 \\rightarrow 4 \\rightarrow 4 \\rightarrow 2$. . Each GCNConv layer is enhanced by a **tanh** non-linearity. A **linear transformation** (`torch.nn.Linear`) acts as a classifier and maps the output of the $3^{rd}$ **tanh** to one of the 4 categories.\n",
    "\n",
    "Finally, we create an object `model` of the `GCN` class.\n",
    "\n",
    "<span style=\"color:red\">     **DOUBTs:** WHY DO WE NEED THE `tanh`? WHAT IS IT'S FUNCTION?    </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0a91dbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GCNConv(34, 4)\n",
      "  (conv2): GCNConv(4, 4)\n",
      "  (conv3): GCNConv(4, 2)\n",
      "  (classifier): Linear(in_features=2, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#import torch\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):#define the layers of our GNN and initializes them\n",
    "        super().__init__()\n",
    "        torch.manual_seed(1234)#sets the seed for random number generation\n",
    "        self.conv1 = GCNConv(dataset.num_features, 4)\n",
    "        self.conv2 = GCNConv(4, 4)\n",
    "        self.conv3 = GCNConv(4, 2)\n",
    "        self.classifier = torch.nn.Linear(2, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data): #defines the computation flow of our GNN\n",
    "        h = self.conv1(data.x, data.edge_index)\n",
    "        h = h.tanh()\n",
    "        h = self.conv2(h, data.edge_index)\n",
    "        h = h.tanh()\n",
    "        h = self.conv3(h, data.edge_index)\n",
    "        h = h.tanh()  # Final GNN embedding space.\n",
    "        \n",
    "        # Apply a final (linear) classifier.\n",
    "        out = self.classifier(h)\n",
    "\n",
    "        return out, h #returns both the output of the final classifier as well as the final node embeddings produced by our GNN\n",
    "\n",
    "model = GCN() \n",
    "print(model) #prints a summary of our model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d37b0b4",
   "metadata": {},
   "source": [
    "Here, `torch.nn.Linear` applies the following linear transformation to the input `x`: \n",
    "\n",
    "$$\\mathbf{y} = \\mathbf{x}\\mathbf{A}^\\mathbf{T} + \\mathbf{b}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2a4482df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=3, out_features=2, bias=True)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m=torch.nn.Linear(3,2)#computes (xA^T+b) where, x is the feature vector, b is the bias vector\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ac3194fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0592,  0.0376,  0.0243],\n",
       "        [-0.5017,  0.5573,  0.5512]], requires_grad=True)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.weight#A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "702fbfe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.3975,  0.1428], requires_grad=True)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.bias#b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "55a28ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5541,  1.4976, -0.4817]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.randn(1,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8b4d79f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3856,  0.9899]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(x)#forward pass of the linear classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4175b0a",
   "metadata": {},
   "source": [
    "## Training the GNN\n",
    "\n",
    "First, we define a loss critertion (here, [`CrossEntropyLoss`](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "bded726b",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da6447b",
   "metadata": {},
   "source": [
    "Then, we initialize a stochastic gradient optimizer (here, [`Adam`](https://pytorch.org/docs/stable/optim.html?highlight=adam#torch.optim.Adam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c99f9f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f00fe5",
   "metadata": {},
   "source": [
    "After that, we perform multiple rounds of optimization, where each round consists of a forward and backward pass to compute the gradients of our model parameters w.r.t. to the loss derived from the forward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "824f1b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(401):\n",
    "    optimizer.zero_grad()  # Clear gradients.\n",
    "    out, h = model(dataset[0])  # Perform a single forward pass.\n",
    "    loss = criterion(out[dataset[0].train_mask], dataset[0].y[dataset[0].train_mask])  # Compute the loss solely based on the training nodes.\n",
    "    loss.backward()  # Derive gradients.\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5edba21",
   "metadata": {},
   "source": [
    "**Final node embeddings produced by the trained GNN:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1d508ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9959, -0.9922],\n",
       "        [-1.0000, -0.4081],\n",
       "        [-0.9997,  0.9750],\n",
       "        [-0.9993, -0.5114],\n",
       "        [ 0.9920, -0.9936],\n",
       "        [ 0.9982, -0.9984],\n",
       "        [ 0.9982, -0.9984],\n",
       "        [-0.9955, -0.0980],\n",
       "        [-0.9919,  0.9885],\n",
       "        [-0.9734,  0.9906],\n",
       "        [ 0.9921, -0.9936],\n",
       "        [-0.8716, -0.7853],\n",
       "        [-0.9762, -0.7062],\n",
       "        [-0.9956,  0.5316],\n",
       "        [-0.9540,  0.9966],\n",
       "        [-0.9531,  0.9966],\n",
       "        [ 0.9990, -0.9962],\n",
       "        [-0.9771, -0.6140],\n",
       "        [-0.9515,  0.9969],\n",
       "        [-0.9804,  0.4159],\n",
       "        [-0.9462,  0.9966],\n",
       "        [-0.9808, -0.5847],\n",
       "        [-0.9519,  0.9966],\n",
       "        [-0.0488,  0.9993],\n",
       "        [ 0.9959,  0.9929],\n",
       "        [ 0.9927,  0.9942],\n",
       "        [-0.9637,  0.9987],\n",
       "        [ 0.4140,  0.9964],\n",
       "        [-0.7756,  0.9934],\n",
       "        [-0.9688,  0.9996],\n",
       "        [-0.9927,  0.9875],\n",
       "        [ 0.6807,  0.9952],\n",
       "        [-0.9999,  1.0000],\n",
       "        [-1.0000,  1.0000]], grad_fn=<TanhBackward0>)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_embeddings_per_node = model(dataset[0])[1]\n",
    "new_embeddings_per_node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4c16ce",
   "metadata": {},
   "source": [
    "**Probability of a node to belong to each label:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d5db31b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1725,  5.4453, -5.5782,  0.1491],\n",
       "        [ 1.4741,  3.7828, -3.9650, -1.4976],\n",
       "        [ 5.3494, -0.1770, -0.1143, -5.3670],\n",
       "        [ 1.1832,  4.0769, -4.2505, -1.2067],\n",
       "        [-4.8904,  0.8330,  0.5678,  6.1149],\n",
       "        [-4.9185,  0.8322,  0.5738,  6.1468],\n",
       "        [-4.9185,  0.8322,  0.5738,  6.1468],\n",
       "        [ 2.3326,  2.8850, -3.0883, -2.3520],\n",
       "        [ 5.3686, -0.2334, -0.0530, -5.3813],\n",
       "        [ 5.3309, -0.2825,  0.0101, -5.3320],\n",
       "        [-4.8906,  0.8328,  0.5681,  6.1151],\n",
       "        [ 0.1127,  4.5642, -4.6176, -0.0572],\n",
       "        [ 0.5824,  4.5808, -4.7212, -0.5922],\n",
       "        [ 4.0971,  1.0829, -1.3361, -4.1140],\n",
       "        [ 5.3014, -0.3446,  0.0868, -5.2903],\n",
       "        [ 5.2993, -0.3468,  0.0897, -5.2876],\n",
       "        [-4.9145,  0.8240,  0.5824,  6.1434],\n",
       "        [ 0.8429,  4.3189, -4.4672, -0.8528],\n",
       "        [ 5.2966, -0.3513,  0.0954, -5.2839],\n",
       "        [ 3.7369,  1.3787, -1.6110, -3.7447],\n",
       "        [ 5.2830, -0.3630,  0.1112, -5.2670],\n",
       "        [ 0.9339,  4.2436, -4.3971, -0.9461],\n",
       "        [ 5.2965, -0.3495,  0.0933, -5.2840],\n",
       "        [ 3.1625, -2.4544,  2.8947, -2.5832],\n",
       "        [ 0.6671, -4.8624,  6.1093,  0.5680],\n",
       "        [ 0.6785, -4.8586,  6.1028,  0.5545],\n",
       "        [ 5.3305, -0.3283,  0.0629, -5.3254],\n",
       "        [ 2.0567, -3.5209,  4.3186, -1.1869],\n",
       "        [ 4.8695, -0.7498,  0.6299, -4.7464],\n",
       "        [ 5.3450, -0.3189,  0.0495, -5.3431],\n",
       "        [ 5.3679, -0.2290, -0.0580, -5.3811],\n",
       "        [ 1.4210, -4.1370,  5.1405, -0.3837],\n",
       "        [ 5.4198, -0.2480, -0.0455, -5.4374],\n",
       "        [ 5.4201, -0.2477, -0.0459, -5.4378]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_label_per_node = model(dataset[0])[0]\n",
    "new_label_per_node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c71902",
   "metadata": {},
   "source": [
    "A node is predicted to have a label that has the highest probability.\n",
    "\n",
    "Since only 4 nodes are labeled in the entire dataset, we present below their labels as predicted by the trained GNN and as mentioned in the dataset. This would help us to get an understanding of the training accuracy achieved by the GNN. Due to lack of any more labeled nodes, we don't have test set for measuring test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "df5dad96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 3, 0, 2])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_label_per_node[dataset[0].train_mask].argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "0f6395d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 3, 0, 2])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].y[dataset[0].train_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e514e03",
   "metadata": {},
   "source": [
    "TO DO:\n",
    "----------\n",
    "1. Print the evolution of weight matrix during the training of GNN. Print all parameters of importance during training of GNN.\n",
    "2. Implement the optional exercise of Cora exercise.\n",
    "3. Implement an MLP and check its performance in this case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
