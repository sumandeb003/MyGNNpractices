{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20dc944b",
   "metadata": {},
   "source": [
    "At first, we need a dataset for training, validating and testing the Graph Neural Network (GNN). We load the Cora dataset (available in PyTorch Geometric framework) in this case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ebe555e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38773b0",
   "metadata": {},
   "source": [
    "Next, we import the libraries required for implementing a 2-layered GNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e23f64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import GCNConv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f558f1",
   "metadata": {},
   "source": [
    "In the following cell, we implement a 2-layered GNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5f8e403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class GCN(torch.nn.Module):#torch.nn.Module is the base class for all neural network modules in PyTorch \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)#GCNConv() performs message computation, aggregation of the messages, and then, updating of the node embeddings. The 1st parameter 'number of input features per node' and the 2nd argument 'number of features per output' are provided for initializing the parameters of the class GCNConv.\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index#'x' represents the vector of node features and edge_index represents the adjacency matrix for connectivity\n",
    "\n",
    "        x = self.conv1(x, edge_index)#conv1.forward() gets called here. The arguments 'x' and 'edge_index' are passed as inputs to forward().\n",
    "        x = F.relu(x)#Applying Relu activation on the result of the above graph-convolution operation.\n",
    "        \n",
    "        x = F.dropout(x, training=self.training)#Randomly zero some of the elements of the input tensor 'x' with probability p(default: 0.5) using samples from a Bernoulli distribution.Also, the mode is set to 'training' because Dropout behaves differently during training and testing.\n",
    "        \n",
    "        x = self.conv2(x, edge_index)#conv2.forward() gets called here. The arguments 'x' and 'edge_index' are passed as inputs to forward().\n",
    "        return F.log_softmax(x, dim=1)#Applying softmax activation on the result of the above graph-convolution operation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f87f765",
   "metadata": {},
   "source": [
    "Then, we choose the device on which we want to deploy the GNN and the training dataset.\n",
    "\n",
    "A **torch.device** is an object representing the device on which a torch.Tensor is or will be allocated. The torch.device contains a device type ('cpu', 'cuda' or 'mps') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7104f29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172f14a3",
   "metadata": {},
   "source": [
    "Next, we move the GNN parameters to the chosen device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9c47798",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615e2f99",
   "metadata": {},
   "source": [
    "Also, we move the dataset to the chosen device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf8a9dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset[0].to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd3ae1b",
   "metadata": {},
   "source": [
    "Then, we choose the optimization algorithm (from the *torch.optim* package) for training/optimizing the parameters of our GNN. As an input, we provided *model.parameters()* to denote which parameters (tensors) to optimize. We also defined the decay constant and learning rate (lr)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fc05fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453ed991",
   "metadata": {},
   "source": [
    "Next, we set the mode of GCN module (torch.nn.Module) to training. '*model.train()*' simple changes the '*self.training*' flag via '*self.training = training*' recursively for all modules. \n",
    "\n",
    "**Note**: By default, the mode is set to training and that is why they omit '*model.train()*' call. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "087ebc64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (conv1): GCNConv(1433, 16)\n",
       "  (conv2): GCNConv(16, 7)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c309fd44",
   "metadata": {},
   "source": [
    "Then, we train the GCN module for 200 epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0f57cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()#Initializes the gradients to zero at the beginning of each epoch\n",
    "    out = model(data)#Calls the 'forward' method in the class GCN and stores the output/prediction of the network.\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])#Calculates the negative log likelihood loss (nll) between original ('data.y') and predicted data ('out') points\n",
    "    loss.backward()#Backward pass for computing the gradients of the loss w.r.t to learnable parameters\n",
    "    optimizer.step()#Updates the learnt parameters at the end of each epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38027baf",
   "metadata": {},
   "source": [
    "Next, we set the mode of GCN module (torch.nn.Module) to testing. This is equivalent to executing: ***model.train(mode=False)***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01118dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (conv1): GCNConv(1433, 16)\n",
       "  (conv2): GCNConv(16, 7)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5e9879",
   "metadata": {},
   "source": [
    "Obtain the predicted class by storing the output class that has max probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef80d57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(data).argmax(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe00cc6d",
   "metadata": {},
   "source": [
    "Compute the total number of correct predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e77415d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035bbaba",
   "metadata": {},
   "source": [
    "Finally, we compute and print the accuracy performance of the GNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26a96a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7880\n"
     ]
    }
   ],
   "source": [
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
